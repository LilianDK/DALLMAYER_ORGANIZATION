# DALLMAYER_ORGANIZATION
This repo is just for sharing and organizing stuff.

Timeline:
- 4. Juli 2024, 16:15 Uhr: Kick-Off-Veranstaltung (digital) DONE WE WERE THERE (see minutes from kick-off meeting 04.07.2024)
- 8. Juli 2024, bis 23:59 Uhr: Registrierung DONE
- 7. Oktober 2024, 16:15 Uhr: Zwischenberichtsveranstaltung (digital)
- 17. November 2024, bis 23:59 Uhr: Abgabe der Resultate
- 17. Januar 2025, 16:15 Uhr: Abschlussveranstaltung und Bekanntgabe des Siegers (digital)
- 3. März 2025: Auszeichnung im Rahmen der DHd-Tagung 2025 in Bielefeld

Expected Deliverable:
- PDF in DE or EN, 200-300 words "Begründung und Kontextualisierung der Fragestellung" ASAP
- Jupyter Notebook with title "_code.ipynb" (restricted to Python, R , Java) IN NOVEMBER
- PDF with title "_text.pdf" in DE or EN IN NOVEMBER

Evaluation Criteria:
- Eine kreative geisteswissenschaftliche Fragestellung, die die Analyse von Big Data begründet und voraussetzt.
- Eine kritische und facettenreiche Analyse des Datensatzes.
- Einsatz von kreativen und möglichst generalisierbaren datenwissenschaftlichen Methoden zur Identifizierung und Beseitigung von Mängeln im Datensatz.
- Für Ansatz A: Ein solides Argument für die fachwissenschaftliche Antwort auf die gestellte Frage.
- Für Ansatz B: Entwicklung eines effizienten Plans für das Digitalisierungsverfahren der Zeitungen, der den FAIR-Prinzipien entspricht.

Further information:
- https://hermes-hub.de/formate/challenges/challenges-ausschreibungen/challenge24_1.html

Contacts:
- hermes.challenges@uni-marburg.de
- https://hermes-data.slack.com

Data:
- German language news paper articles incl. metadata from 1914 to 1945  
- https://hessenbox.uni-marburg.de/getlink/fi5WMibFaZX2ueh4xBvqwM/Datensatz (159 GB)
- There is additional image data up to 2 TB
  
# Minutes from kick-off meeting 04.07.2024
### Data
- We are receiving the raw data right after their OCR pre-processing on which we shall work
- They recommend not to use the API because data is changing there. Instead they ask us to download the data from the given link
- If we do not have enough disk space we can work with a fraction of the provided data instead of the total dataset
- We must not enrich the data with other data sources because of licensing etc.

### IP
- The IP remains on our side. They offer to support in publishing on their hermes blog
- The scans of the original sources are also available and the licensing is individual per outlet etc. It is assumed that we could retrieve licinsing information from the API

### Expected deliverables
- We have to deliver 2 things: (1) Forschungsfrage/Fragestellung und (2) Ansatz A oder Ansatz B
